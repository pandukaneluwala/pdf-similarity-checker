{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install PyMuPDF python-docx scikit-learn -q\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "from docx import Document\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# Instructions for users\n",
        "print(\"\"\"\n",
        "PDF and DOCX Similarity Checker\n",
        "------------------------------\n",
        "1. Upload your PDF or Word (.docx) files (e.g., student assignments).\n",
        "2. The script will extract text and compare for 95%+ similarity.\n",
        "3. Results are saved as 'similarity_report.txt' and downloaded automatically.\n",
        "4. No file contents are stored or displayed for privacy.\n",
        "\"\"\")\n",
        "\n",
        "# Step 1: Set up directory\n",
        "upload_dir = '/content/uploads'\n",
        "os.makedirs(upload_dir, exist_ok=True)\n",
        "\n",
        "# Step 2: Upload files\n",
        "print(\"Please upload your PDF or Word (.docx) files...\")\n",
        "uploaded = files.upload()\n",
        "for filename, content in uploaded.items():\n",
        "    if filename.lower().endswith(('.pdf', '.docx')):\n",
        "        with open(os.path.join(upload_dir, filename), 'wb') as f:\n",
        "            f.write(content)\n",
        "    else:\n",
        "        print(f\"Skipped {filename}: Not a PDF or .docx file\")\n",
        "\n",
        "# Step 3: Extract text from files\n",
        "print(\"\\nExtracting text from files...\")\n",
        "file_texts = []\n",
        "file_names = []\n",
        "for filename in os.listdir(upload_dir):\n",
        "    try:\n",
        "        text = ''\n",
        "        file_path = os.path.join(upload_dir, filename)\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            with fitz.open(file_path) as doc:\n",
        "                for page in doc:\n",
        "                    page_text = page.get_text()\n",
        "                    if page_text:\n",
        "                        text += page_text + '\\n'\n",
        "        elif filename.lower().endswith('.docx'):\n",
        "            doc = Document(file_path)\n",
        "            for para in doc.paragraphs:\n",
        "                if para.text:\n",
        "                    text += para.text + '\\n'\n",
        "        # Remove student names (customizable)\n",
        "        text = re.sub(r'(?:Student )?Name: [A-Za-z\\s]+', '', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'[A-Za-z\\s]+@student\\.edu', '', text, flags=re.IGNORECASE)\n",
        "        if text.strip():\n",
        "            file_texts.append(text)\n",
        "            file_names.append(filename)\n",
        "        else:\n",
        "            print(f\"Skipped {filename}: No extractable text\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "# Step 4: Compare for 95%+ similarity\n",
        "if len(file_texts) < 2:\n",
        "    print(\"\\n❌ Not enough valid documents with extractable text.\")\n",
        "else:\n",
        "    print(\"\\nComparing files for 95%+ similarity...\")\n",
        "    try:\n",
        "        # TF-IDF Vectorization + Cosine Similarity\n",
        "        vectorizer = TfidfVectorizer(stop_words='english').fit_transform(file_texts)\n",
        "        similarity_matrix = cosine_similarity(vectorizer)\n",
        "\n",
        "        # Threshold for 95%+ similarity\n",
        "        threshold = 0.95\n",
        "        results = []\n",
        "        for i in range(len(file_names)):\n",
        "            for j in range(i + 1, len(file_names)):\n",
        "                score = similarity_matrix[i][j]\n",
        "                if score >= threshold:\n",
        "                    results.append(f\"{file_names[i]} <--> {file_names[j]} : {score:.2f}\")\n",
        "\n",
        "        # Step 5: Save and download results\n",
        "        output_file = '/content/similarity_report.txt'\n",
        "        if results:\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(\"Similarity Results (95%+ Threshold)\\n\")\n",
        "                f.write(\"----------------------------------\\n\")\n",
        "                for result in results:\n",
        "                    f.write(result + '\\n')\n",
        "            print(f\"\\nFound {len(results)} pairs with 95%+ similarity. Downloading results...\")\n",
        "            files.download(output_file)\n",
        "        else:\n",
        "            print(\"\\nNo pairs with 95%+ similarity found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during comparison: {e}\")\n",
        "\n",
        "# Step 6: Clean up for privacy\n",
        "print(\"\\nCleaning up temporary files...\")\n",
        "try:\n",
        "    for file in os.listdir(upload_dir):\n",
        "        os.remove(os.path.join(upload_dir, file))\n",
        "    os.rmdir(upload_dir)\n",
        "except Exception as e:\n",
        "    print(f\"Error cleaning up: {e}\")\n",
        "print(\"Done! All temporary files deleted.\")"
      ],
      "metadata": {
        "id": "WOdpZLuqXCXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}